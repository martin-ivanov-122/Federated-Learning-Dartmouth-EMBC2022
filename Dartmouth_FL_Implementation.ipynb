{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913bc926-dc82-4004-b8bb-4d2e9e33bd99",
   "metadata": {
    "id": "913bc926-dc82-4004-b8bb-4d2e9e33bd99"
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c3f6cf-61a1-4d0a-bc6b-99046bea0600",
   "metadata": {
    "id": "55c3f6cf-61a1-4d0a-bc6b-99046bea0600",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Requirement already satisfied: imutils in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: tensorflow in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in f:\\users\\enigmen\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install imutils\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede890ba-acca-4515-a55f-b2d342a02686",
   "metadata": {
    "id": "ede890ba-acca-4515-a55f-b2d342a02686"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0142576-c94a-4768-84fa-882c88fb3a41",
   "metadata": {
    "id": "d0142576-c94a-4768-84fa-882c88fb3a41"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#Import LSTM\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import os \n",
    "from fl_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87671998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12aea0-e84e-4bdb-9b7b-88ac058edbed",
   "metadata": {
    "id": "ad12aea0-e84e-4bdb-9b7b-88ac058edbed"
   },
   "source": [
    "# Data Set-Up - Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d67f1",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818e8892-ddb4-4bd8-9e81-98880cc7f8d5",
   "metadata": {
    "id": "818e8892-ddb4-4bd8-9e81-98880cc7f8d5",
    "outputId": "1c6b5bf1-6f56-4372-9b90-81ef15a854fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location Variance</th>\n",
       "      <th>Time in Location Cluster 1</th>\n",
       "      <th>Time in Location Cluster 2</th>\n",
       "      <th>Time in Location Cluster 3</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Normalized entropy</th>\n",
       "      <th>Percentage At Home</th>\n",
       "      <th>Percentage Moving</th>\n",
       "      <th>Total Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195.256628</td>\n",
       "      <td>0.454980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>0.231464</td>\n",
       "      <td>1180.906882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.519551</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.086628</td>\n",
       "      <td>0.556916</td>\n",
       "      <td>0.506927</td>\n",
       "      <td>0.771882</td>\n",
       "      <td>0.214763</td>\n",
       "      <td>106.223128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.694717</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259013</td>\n",
       "      <td>0.373677</td>\n",
       "      <td>0.667777</td>\n",
       "      <td>0.151203</td>\n",
       "      <td>193.611207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.427754</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369302</td>\n",
       "      <td>0.532791</td>\n",
       "      <td>0.927756</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>7.291102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.437547</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.369029</td>\n",
       "      <td>0.335905</td>\n",
       "      <td>0.895028</td>\n",
       "      <td>0.406630</td>\n",
       "      <td>199.593622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location Variance  Time in Location Cluster 1  Time in Location Cluster 2  \\\n",
       "0         195.256628                    0.454980                    0.000000   \n",
       "1           0.000011                    0.519551                    0.000657   \n",
       "2           0.000936                    0.694717                    0.000842   \n",
       "3           0.000010                    0.427754                    0.000857   \n",
       "4           0.026826                    0.437547                    0.000363   \n",
       "\n",
       "   Time in Location Cluster 3   Entropy  Normalized entropy  \\\n",
       "0                    0.000000  0.358298            0.000000   \n",
       "1                    0.086628  0.556916            0.506927   \n",
       "2                    0.000000  0.259013            0.373677   \n",
       "3                    0.000000  0.369302            0.532791   \n",
       "4                    0.000606  0.369029            0.335905   \n",
       "\n",
       "   Percentage At Home  Percentage Moving  Total Distance  \n",
       "0            0.942076           0.231464     1180.906882  \n",
       "1            0.771882           0.214763      106.223128  \n",
       "2            0.667777           0.151203      193.611207  \n",
       "3            0.927756           0.040263        7.291102  \n",
       "4            0.895028           0.406630      199.593622  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'loc_view.csv'\n",
    "columns_lab = ['Location Variance','Time in Location Cluster 1','Time in Location Cluster 2','Time in Location Cluster 3','Entropy','Normalized entropy','Percentage At Home','Percentage Moving','Total Distance']\n",
    "\n",
    "location_view = pd.read_csv(filename,names=columns_lab)\n",
    "\n",
    "location_view.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ed626",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb821c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHQ9 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PHQ9 Score\n",
       "0         1.0\n",
       "1         2.0\n",
       "2         2.0\n",
       "3         2.0\n",
       "4         2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'phq_score.csv'\n",
    "columns_lab=['PHQ9 Score']\n",
    "\n",
    "label = pd.read_csv(filename, names=columns_lab)\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4997105-f823-43de-948a-376507889565",
   "metadata": {},
   "source": [
    "## Feature Matrix with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d5591f-ed29-48be-9ea9-83509b3cb122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location Variance</th>\n",
       "      <th>Time in Location Cluster 1</th>\n",
       "      <th>Time in Location Cluster 2</th>\n",
       "      <th>Time in Location Cluster 3</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Normalized entropy</th>\n",
       "      <th>Percentage At Home</th>\n",
       "      <th>Percentage Moving</th>\n",
       "      <th>Total Distance</th>\n",
       "      <th>PHQ9 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195.256628</td>\n",
       "      <td>0.454980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>0.231464</td>\n",
       "      <td>1180.906882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.519551</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.086628</td>\n",
       "      <td>0.556916</td>\n",
       "      <td>0.506927</td>\n",
       "      <td>0.771882</td>\n",
       "      <td>0.214763</td>\n",
       "      <td>106.223128</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.694717</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259013</td>\n",
       "      <td>0.373677</td>\n",
       "      <td>0.667777</td>\n",
       "      <td>0.151203</td>\n",
       "      <td>193.611207</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.427754</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369302</td>\n",
       "      <td>0.532791</td>\n",
       "      <td>0.927756</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>7.291102</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.437547</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.369029</td>\n",
       "      <td>0.335905</td>\n",
       "      <td>0.895028</td>\n",
       "      <td>0.406630</td>\n",
       "      <td>199.593622</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location Variance  Time in Location Cluster 1  Time in Location Cluster 2  \\\n",
       "0         195.256628                    0.454980                    0.000000   \n",
       "1           0.000011                    0.519551                    0.000657   \n",
       "2           0.000936                    0.694717                    0.000842   \n",
       "3           0.000010                    0.427754                    0.000857   \n",
       "4           0.026826                    0.437547                    0.000363   \n",
       "\n",
       "   Time in Location Cluster 3   Entropy  Normalized entropy  \\\n",
       "0                    0.000000  0.358298            0.000000   \n",
       "1                    0.086628  0.556916            0.506927   \n",
       "2                    0.000000  0.259013            0.373677   \n",
       "3                    0.000000  0.369302            0.532791   \n",
       "4                    0.000606  0.369029            0.335905   \n",
       "\n",
       "   Percentage At Home  Percentage Moving  Total Distance  PHQ9 Score  \n",
       "0            0.942076           0.231464     1180.906882         1.0  \n",
       "1            0.771882           0.214763      106.223128         2.0  \n",
       "2            0.667777           0.151203      193.611207         2.0  \n",
       "3            0.927756           0.040263        7.291102         2.0  \n",
       "4            0.895028           0.406630      199.593622         2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine features and labels into 1 dataframe\n",
    "frames = [location_view,label]\n",
    "df_feat = pd.concat(frames,axis=1)\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef1285-6e3a-44d5-9918-22e5e613a80c",
   "metadata": {
    "id": "8eef1285-6e3a-44d5-9918-22e5e613a80c"
   },
   "source": [
    "# Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f78a970-fc58-48eb-bc40-5b8f71cd52b7",
   "metadata": {
    "id": "3f78a970-fc58-48eb-bc40-5b8f71cd52b7"
   },
   "outputs": [],
   "source": [
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(location_view, \n",
    "                                                    label, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc62619-ffc1-42d7-b3c8-a7ae014da234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location Variance</th>\n",
       "      <th>Time in Location Cluster 1</th>\n",
       "      <th>Time in Location Cluster 2</th>\n",
       "      <th>Time in Location Cluster 3</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Normalized entropy</th>\n",
       "      <th>Percentage At Home</th>\n",
       "      <th>Percentage Moving</th>\n",
       "      <th>Total Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.202610</td>\n",
       "      <td>0.176754</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>0.639859</td>\n",
       "      <td>0.582425</td>\n",
       "      <td>0.525161</td>\n",
       "      <td>0.130193</td>\n",
       "      <td>344.788983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.246223</td>\n",
       "      <td>0.123674</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.603578</td>\n",
       "      <td>0.870780</td>\n",
       "      <td>0.657539</td>\n",
       "      <td>0.106491</td>\n",
       "      <td>505.313568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.148557</td>\n",
       "      <td>0.441007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.361050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>50.046171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.142359</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.439947</td>\n",
       "      <td>0.634710</td>\n",
       "      <td>0.943282</td>\n",
       "      <td>0.208275</td>\n",
       "      <td>75.138250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.438226</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.440291</td>\n",
       "      <td>0.635206</td>\n",
       "      <td>0.822120</td>\n",
       "      <td>0.084332</td>\n",
       "      <td>32.703150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Location Variance  Time in Location Cluster 1  Time in Location Cluster 2  \\\n",
       "30           0.000631                    0.202610                    0.176754   \n",
       "26           0.000898                    0.246223                    0.123674   \n",
       "6            0.148557                    0.441007                    0.000000   \n",
       "27           0.142359                    0.453373                    0.021064   \n",
       "24           0.000163                    0.438226                    0.020174   \n",
       "\n",
       "    Time in Location Cluster 3   Entropy  Normalized entropy  \\\n",
       "30                     0.00156  0.639859            0.582425   \n",
       "26                     0.00000  0.603578            0.870780   \n",
       "6                      0.00000  0.361050            0.000000   \n",
       "27                     0.00000  0.439947            0.634710   \n",
       "24                     0.00000  0.440291            0.635206   \n",
       "\n",
       "    Percentage At Home  Percentage Moving  Total Distance  \n",
       "30            0.525161           0.130193      344.788983  \n",
       "26            0.657539           0.106491      505.313568  \n",
       "6             0.999034           0.156200       50.046171  \n",
       "27            0.943282           0.208275       75.138250  \n",
       "24            0.822120           0.084332       32.703150  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d64ed9-312e-48e6-84d3-e93c8b583f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Location Variance  Time in Location Cluster 1  Time in Location Cluster 2  \\\n",
      "33           0.000528                    0.533908                    0.000000   \n",
      "36           0.001272                    0.658768                    0.000986   \n",
      "4            0.026826                    0.437547                    0.000363   \n",
      "13           0.071124                    0.403649                    0.000000   \n",
      "\n",
      "    Time in Location Cluster 3   Entropy  Normalized entropy  \\\n",
      "33                    0.000000  0.335044            0.000000   \n",
      "36                    0.000000  0.281783            0.406527   \n",
      "4                     0.000606  0.369029            0.335905   \n",
      "13                    0.000000  0.366194            0.000000   \n",
      "\n",
      "    Percentage At Home  Percentage Moving  Total Distance  \n",
      "33            0.872586           0.259407       72.083169  \n",
      "36            0.921966           0.074548       10.342050  \n",
      "4             0.895028           0.406630      199.593622  \n",
      "13            0.977021           0.126791       37.798361  \n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e884932f-bf6a-4a9b-b1b5-a95410351f7e",
   "metadata": {
    "id": "e884932f-bf6a-4a9b-b1b5-a95410351f7e",
    "outputId": "cc7607d7-8f70-40d1-94ae-496db2fb6a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PHQ9 Score\n",
      "0          1.0\n",
      "1          2.0\n",
      "2          2.0\n",
      "3          2.0\n",
      "4          2.0\n",
      "5          0.0\n",
      "6          2.0\n",
      "7          1.0\n",
      "8          2.0\n",
      "9          1.0\n",
      "10         0.0\n",
      "11         0.0\n",
      "12         1.0\n",
      "13         0.0\n",
      "14         2.0\n",
      "15         2.0\n",
      "16         1.0\n",
      "17         2.0\n",
      "18         2.0\n",
      "19         0.0\n",
      "20         2.0\n",
      "21         1.0\n",
      "22         1.0\n",
      "23         2.0\n",
      "24         2.0\n",
      "25         0.0\n",
      "26         0.0\n",
      "27         2.0\n",
      "28         1.0\n",
      "29         1.0\n",
      "30         0.0\n",
      "31         2.0\n",
      "32         0.0\n",
      "33         0.0\n",
      "34         0.0\n",
      "35         1.0\n",
      "36         2.0\n",
      "37         2.0\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be9782-518e-4762-a72e-40956766ebc2",
   "metadata": {
    "id": "19be9782-518e-4762-a72e-40956766ebc2"
   },
   "source": [
    "# Federated Learning Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e048e2e-86e3-42e6-aedf-e95e21df218f",
   "metadata": {
    "id": "3e048e2e-86e3-42e6-aedf-e95e21df218f"
   },
   "source": [
    "## Seperate Subject Data to each Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf04e794-5f71-4055-b29a-5bf8df8ebc91",
   "metadata": {
    "id": "bf04e794-5f71-4055-b29a-5bf8df8ebc91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u00', 'u01', 'u02', 'u03', 'u04', 'u05', 'u06', 'u07', 'u08', 'u09', 'u10', 'u11', 'u12', 'u13', 'u14', 'u15', 'u16', 'u17', 'u18', 'u19', 'u20', 'u21', 'u22', 'u23', 'u24', 'u25', 'u26', 'u27', 'u28', 'u29', 'u30', 'u31', 'u32', 'u33']\n"
     ]
    }
   ],
   "source": [
    "#Seperate Subjects\n",
    "# Subject /\n",
    "s1 =  [('u0'+str(x)) for x in range(9 + 1)]\n",
    "s2 =  ['u'+str(x) for x in range(10,34)]\n",
    "subject_names = s1+s2\n",
    "print(subject_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324d630-bb3d-4bfb-9014-71b2f7c02371",
   "metadata": {},
   "source": [
    "## Batch Data to each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "361ef5a3-f607-4bec-b584-47b84a93392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 2, 9), (None, 2, 1)), types: (tf.float64, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "subjects_batched = dict()\n",
    "x=0\n",
    "for i in range(0,len(subject_names),2):\n",
    "    subjects_batched[subject_names[i]] = tf.data.Dataset.from_tensors((X_train.iloc[i:i+2,:], y_train.iloc[i:i+2,:])).batch(len(y_train))\n",
    "\n",
    "#process and batch the test set \n",
    "test_batched = tf.data.Dataset.from_tensors((X_test.iloc[0:2,:], y_test.iloc[0:2,:])).batch(len(y_test))\n",
    "print(test_batched)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039bba31-0761-4e29-a2e5-27f35e83438e",
   "metadata": {
    "id": "039bba31-0761-4e29-a2e5-27f35e83438e"
   },
   "source": [
    "## 3 Layer MLP (multi-layer perception) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cce1670-5c73-4240-8b92-50f18f0136fa",
   "metadata": {
    "id": "7cce1670-5c73-4240-8b92-50f18f0136fa"
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape_x,shape_y, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape_x,shape_y)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a93797-912b-4e45-a506-246a5ce1529e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa19009-ffad-4072-a71d-d86acad7e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM:\n",
    "    @staticmethod\n",
    "    def build(shap_x,shape_y,classes):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(4, input_shape=(shap_x, shape_y)))\n",
    "        model.add(Dense(1))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c1185-a4c7-4a54-a6b5-a2dabfff585b",
   "metadata": {
    "id": "736c1185-a4c7-4a54-a6b5-a2dabfff585b"
   },
   "source": [
    "## Declearing model optimizer, loss function and a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "992f9917-d267-45d7-b56f-4875459d2e7e",
   "metadata": {
    "id": "992f9917-d267-45d7-b56f-4875459d2e7e"
   },
   "outputs": [],
   "source": [
    "#Learning Rate\n",
    "lr = 0.01 \n",
    "\n",
    "# number global epochs (aggregations)\n",
    "comms_round = 10\n",
    "\n",
    "#Loss Function\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "#Evaluation Metric\n",
    "metrics = ['accuracy']\n",
    "\n",
    "#Model optimization using SGD (Stochastic Gradient Descent)\n",
    "optimizer = SGD(learning_rate=lr, decay=lr / comms_round, momentum=0.9)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caeee68-a8bd-4550-ac36-318544546770",
   "metadata": {
    "id": "5caeee68-a8bd-4550-ac36-318544546770"
   },
   "source": [
    "# Model Aggregation (Federated Averaging) and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ac02808-0dc4-4a98-94fa-63b1c1553685",
   "metadata": {
    "id": "6ac02808-0dc4-4a98-94fa-63b1c1553685",
    "outputId": "988d0b82-5bf5-4609-dbba-3744a0633d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comm_round: 0 | global_acc: 0.000% | global_loss: 0.0\n",
      "comm_round: 1 | global_acc: 0.000% | global_loss: 0.0\n",
      "comm_round: 2 | global_acc: 0.000% | global_loss: 0.0\n",
      "comm_round: 3 | global_acc: 0.000% | global_loss: 0.0\n",
      "comm_round: 4 | global_acc: 0.000% | global_loss: 0.0\n",
      "comm_round: 5 | global_acc: 0.000% | global_loss: 0.0\n",
      "comm_round: 6 | global_acc: 0.000% | global_loss: nan\n",
      "comm_round: 7 | global_acc: 0.000% | global_loss: nan\n",
      "comm_round: 8 | global_acc: 0.000% | global_loss: nan\n",
      "comm_round: 9 | global_acc: 0.000% | global_loss: nan\n"
     ]
    }
   ],
   "source": [
    "#initialize global model\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(2, 9, 1)\n",
    "        \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    subject_name= list(subjects_batched.keys())\n",
    "    random.shuffle(subject_name)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for subject in subject_name:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(2, 9, 1)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(subjects_batched[subject], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(subjects_batched, subject)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(Xtest, Ytest) in test_batched:\n",
    "        global_acc, global_loss = test_model(Xtest, Ytest, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9e1f6-9784-4380-8ee9-aed1300081b7",
   "metadata": {
    "id": "a5d9e1f6-9784-4380-8ee9-aed1300081b7"
   },
   "source": [
    "# SGD Comparison to Federated Learning Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e878d5-a06d-4e9b-9c35-de3409366f18",
   "metadata": {
    "id": "62e878d5-a06d-4e9b-9c35-de3409366f18",
    "outputId": "bf165c5f-7b11-4abe-d128-04e26b728da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 34, 9), (None, 34, 1)), types: (tf.float64, tf.float64)>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 34, 9), found shape=(None, 9)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-aeba1d607bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#test the SGD global model and print out metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mSGD_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGD_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGD_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Federated-Learning-Dartmouth-EMBC2022\\fl_utils.py\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(X_test, Y_test, model, comm_round)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mcce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;31m#logits = model.predict(X_test, batch_size=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"F:\\Users\\enigmen\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 34, 9), found shape=(None, 9)\n"
     ]
    }
   ],
   "source": [
    "#Creating SGD Dataset with all hyperparameters equal to that of FL, however with a batch size of 320 as there are not multiple independent models or multiple clients to have said models\n",
    "SGD_dataset = tf.data.Dataset.from_tensors((X_train.iloc[:,:], y_train.iloc[:,:])).batch(len(y_train))\n",
    "\n",
    "print(SGD_dataset)\n",
    "\n",
    "\n",
    "#Initializing Model\n",
    "smlp_SGD = SimpleMLP()\n",
    "\n",
    "#Generating model with a shape of 784, and 10 classes\n",
    "SGD_model = smlp_SGD.build(34,9, 1) \n",
    "\n",
    "#Compilation of Model using model paramaters\n",
    "SGD_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# fit the SGD training data to model\n",
    "_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)\n",
    "\n",
    "#test the SGD global model and print out metrics\n",
    "SGD_acc, SGD_loss = test_model(X_train, y_train, SGD_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a683af-063d-442a-a3be-4d2b4182b053",
   "metadata": {
    "id": "00a683af-063d-442a-a3be-4d2b4182b053"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FLExample_Implementation_Martin_Ivanov.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
